import requests

# Consulta el archivo robots.txt del sitio de Wikipedia
print(requests.get("https://www.lanacion.com.ar/robots.txt").text)

'''
El archivo nO prohÃ­be de forma general el scraping. 
â›” Solo restringe el acceso a ciertas rutas, como: 
- /sinbarreras, /newsletters/, /registracion, etc.
- URLs con ?utm_* en los parÃ¡metros.
- Algunas rutas especÃ­ficas como /buscador, /pf/api/..., y ciertos artÃ­culos puntuales.

# ğŸ‘‰ğŸ¼ La pÃ¡gina de feriados https://www.lanacion.com.ar/feriados/2024/ no estÃ¡ bloqueada
# âœ… Se puede hacer scraping de esa pÃ¡gina.
'''